## Shared Task: Parsing from Raw Text to Uniform Meaning Representation

DMR 2026 features a shared task evaluating approaches to automatic prediction of UMR annotation, including sentence graph structure, node attributes, alignment with surface text, and document-level relations. UMR is a relatively new formalism designed for multilingual semantic representation across typologically diverse languages. While based on AMR, it differs substantially, and parsing into UMR remains largely unexplored compared to AMR, which was the focus of CoNLL shared tasks in 2019 and 2020.

UMR datasets now exist for multiple languages. Version 2.0 covers eight typologically diverse languages with varying amounts of annotated data, and newer versions are already available for two of these languages. The shared task uses the most recent version of these datasets for training and testing. A small amount of previously unpublished test sentences will be annotated directly for the shared task. The evaluation will compare several metrics proposed for this type of data—most notably Smatch, the de facto standard for AMR, as well as more recent approaches such as AnCast.

The shared task follows a standard schedule: training and development data will be released early, test sets will be provided several months before the workshop, with limited time for participants to run their parsers. This ensures sufficient time to evaluate results, inform participants, and prepare system descriptions for inclusion in the proceedings, along with an overview and analysis of submissions.

The shared task is led by Daniel Zeman and Jan Štěpánek (Charles University, Prague), both experienced organizers of past shared tasks, including CoNLL and MRP shared tasks on multilingual Semantic Role Labeling, Universal Dependency parsing, multilingual Meaning Representation Parsing, and more.

More details about the shared task will be announced soon.
